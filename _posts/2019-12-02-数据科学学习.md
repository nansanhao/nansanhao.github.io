---
layout:     post
title:      数据科学学习笔记
subtitle:   这是笔者在数据科学学习时所作的笔记。
date:       2019-12-02
author:     南三号
header-img: img/post-bg-e2e-ux.jpg
catalog: true
tags:
    - 机器学习
---

# 数据科学-学习笔记

常见的数据类型

- 表格，点集，时间序列，图像，视频，网页和报纸，网络数据

基本的数据结构

- 度量结构，网络结构，代数结构，拓扑结构，函数结构

数据分析的困难

- 数据量大，数据维度高（核心困难），数据类型复杂，噪音大

算法角度看，处理大数据有两条思路

- 降低算法的复杂度（如随机梯度下降）
- 分布式计算（分治思想）

机器学习的基本方法

- 有监督学习（数据集中的样本带有标签，有明确目标，如回归和分类）
- 无监督学习（数据集中的样本没有标签，没有明确目标，如聚类、降维、排序、密度估计、关联规则挖掘）
- 强化学习（智慧决策的过程，通过过程模拟和观察来不断学习、提高决策能力，如AlphaGo）

过度拟合问题

交叉验证

### 数据预处理

**样本**

**特征**：连续性特征，离散型特征

**度量手段**：算术平均值，中值，极值，分位数，盒图，距离

**缺失值处理**：删除法，均值填补，随机填补，基于模型的填补，

**离群值**处理：

- 检测：基于统计，基于近邻

**特征编码**：将非数值特征转化为数值特征

- 数字编码
- One-Hot编码
- 哑变量编码方法

**数据标准化**

- Z-score标准化
- Min-Max标准化
- 小数定标标准化
- Logistic标准化

**特征离散化**

- 特征的离散化过程是将连续型特征的取值范围划分为若干区间段(bin)，然后使用区间段代替落在该区间段的特征取值
- 步骤：特征排序，切分点选择，区间段分割或者合并
- 类型：等距离散化，等频率离散化，聚类离散化，信息增益离散化，卡方离散化

### 回归模型

回归：用一个或多个自变量来预测因变量的数学方法

变量过多可能会导致过拟合

线性回归（一元和多元）

正则化：

- 岭回归（岭迹分析）
- LASSO回归

非线性回归

- 样条回归
- 径向基网络 
- SVR: SVM for regression
- Regression Tree
- Gaussian process

### 分类模型

一般为两个阶段：

- 分类器训练
- 预测

逻辑回归

K近邻（距离，k-d树）

决策树（不纯度（Gini指数，信息熵，误分率））

- 剪枝

朴素贝叶斯（假设特征独立）

### 集成模型

集成策略：多数投票方法 (majority vote)，平均 (averaging)，加权平均 (weighted averaging)

集成方法：

- Bagging：随机取样，生成多个模型，平均预测值
- Boosting：串行训练多个模型

决策树的局限性：局部最优，分类边界

随机森林算法

### 聚类模型

> 将数据集中相似的样本进行分组的过程

- K-means
- 层次聚类：聚合式聚类(agglomerative clustering)，分拆式聚类(divisive clustering)
- 谱聚类
- DBSCAN（基于密度）



